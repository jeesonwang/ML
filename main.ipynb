{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先设定好要使用哪些模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "from hyperparams_grid import *\n",
    "\n",
    "algo=[\n",
    "    #[BaggingClassifier(), 'BaggingClassifier', grid_bagging],\n",
    "    [KNeighborsClassifier(), 'KNeighborsClassifier',grid_knn],\n",
    "    [GradientBoostingClassifier(), 'GradientBoostingClassifier',grid_gbt],\n",
    "    #[AdaBoostClassifier(), 'AdaBoostClassifier', grid_adaboost],\n",
    "    [RandomForestClassifier(), 'RandomForestClassifier',grid_rf],\n",
    "    [DecisionTreeClassifier(), 'DecisionTreeClassifier',grid_dt],\n",
    "    [GaussianProcessClassifier(), 'GaussianProcessClassifier', grid_gaussian],\n",
    "    #[SVC(), 'SVM tuning',grid_svm],\n",
    "    [GaussianNB(), 'GaussianNB',grid_nb],\n",
    "    [LogisticRegression(), 'LogisticRegression',grid_lr],\n",
    "    [MLPClassifier(), 'MLPClassifier',grid_mlp]\n",
    "    #[ExtraTreesClassifier(), 'ExtraTreesClassifier', grid_extratrees]\n",
    "]\n",
    "\n",
    "smelltype = 'LongMethod'\n",
    "\n",
    "def print_data_model():\n",
    "    for detail in algo:\n",
    "        print(detail[1])\n",
    "        print(detail[0].get_params())\n",
    "\n",
    "\n",
    "print_data_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据导入和数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "LargeClass = pd.read_csv('..\\dataset\\LargeClass.csv', encoding='UTF8')\n",
    "LongMethod = pd.read_csv('..\\dataset\\LongMethod.csv', encoding='UTF8')\n",
    "\n",
    "#将LongMethod的所有Nan值填充为-1\n",
    "LongMethod = LongMethod.fillna(-1)\n",
    "#将LargeClass的所有Nan值填充为-1\n",
    "LargeClass = LargeClass.fillna(-1) \n",
    "\n",
    "#去除'Experince Based '标签列\n",
    "LabelLongMethod = LongMethod['smell']\n",
    "LongMethod = LongMethod.drop('smell', axis=1)\n",
    "\n",
    "#去除'smell'标签列\n",
    "LabelLargeClass = LargeClass['smell']\n",
    "LargeClass = LargeClass.drop('smell', axis=1)\n",
    "\n",
    "#LargeClass标准化\n",
    "mean = LongMethod.mean()\n",
    "std = LongMethod.std()\n",
    "LongMethod = (LongMethod - mean)/std\n",
    "\n",
    "mean = LargeClass.mean()\n",
    "std = LargeClass.std()\n",
    "LargeClass = (LargeClass - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始网格搜索找到每个分类器的在每个fold中的最佳参数\n",
    "\n",
    "**注意：**\n",
    "* 每个fold的最佳参数都不同\n",
    "* 会保存每个分类器在每个fold中的最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning_model/LongMethod/tuning dose not exist\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 1:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[32  0]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 2:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=6)\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.8571428571428571\n",
      "[[32  1]\n",
      " [ 0  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.88      0.98      0.92        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 3:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[35  0]\n",
      " [ 0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 4:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[34  0]\n",
      " [ 0  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 5:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.6666666666666666\n",
      "[[34  0]\n",
      " [ 1  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        34\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.99      0.75      0.83        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 6:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[35  0]\n",
      " [ 0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 7:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=6)\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.6666666666666666\n",
      "[[34  1]\n",
      " [ 0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        35\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.75      0.99      0.83        36\n",
      "weighted avg       0.99      0.97      0.98        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 8:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.9090909090909091\n",
      "[[30  1]\n",
      " [ 0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.92      0.98      0.95        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 9:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.8571428571428571\n",
      "[[32  0]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        32\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.88      0.92        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 10:\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=12)\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[32  0]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 1:\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[32  0]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 2:\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.8571428571428571\n",
      "[[32  1]\n",
      " [ 0  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.88      0.98      0.92        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 3:\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[35  0]\n",
      " [ 0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 4:\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.6666666666666666\n",
      "[[34  0]\n",
      " [ 1  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        34\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.99      0.75      0.83        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 5:\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.6666666666666666\n",
      "[[34  0]\n",
      " [ 1  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        34\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.99      0.75      0.83        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 6:\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[35  0]\n",
      " [ 0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 7:\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.6666666666666666\n",
      "[[34  1]\n",
      " [ 0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        35\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.75      0.99      0.83        36\n",
      "weighted avg       0.99      0.97      0.98        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 8:\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.9090909090909091\n",
      "[[30  1]\n",
      " [ 0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.92      0.98      0.95        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 0.9722\n",
      "fold 9:\n",
      "Accuracy: 0.9722222222222222\n",
      "f-score: 0.8571428571428571\n",
      "[[32  0]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        32\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.88      0.92        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier Accuracy: 1.0000\n",
      "fold 10:\n",
      "Accuracy: 1.0\n",
      "f-score: 1.0\n",
      "[[32  0]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "all\n",
      "DecisionTreeClassifier\n",
      "[[330   3]\n",
      " [  2  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       333\n",
      "         1.0       0.89      0.93      0.91        27\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.94      0.96      0.95       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "all\n",
      "DecisionTreeClassifier\n",
      "[[330   3]\n",
      " [  3  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       333\n",
      "         1.0       0.89      0.89      0.89        27\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.94      0.94      0.94       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tuning_model import tuning_model\n",
    "from default_model import default_model\n",
    "from utils import write_report_result, filter_algo\n",
    "\n",
    "# 先进行过滤\n",
    "algo = filter_algo(algo)\n",
    "smelltype = 'LongMethod'\n",
    "X = LongMethod.to_numpy()\n",
    "y = LabelLongMethod.to_numpy()\n",
    "\n",
    "\n",
    "if algo:\n",
    "    # 网格搜索\n",
    "    tuning_model_scores = tuning_model(X, y, smelltype, algo)\n",
    "    # 默认参数\n",
    "    default_model_scores = default_model(f\"tuning_model\\{smelltype}_data\", smelltype, algo)\n",
    "    tuning_res = write_report_result(tuning_model_scores, f\"tuning_model\\\\{smelltype}\")\n",
    "    default_res = write_report_result(default_model_scores, f\"default_model\\\\{smelltype}\")\n",
    "else:\n",
    "    print(\"All algorithms have been run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "default_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin using ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 每一个fold应用不同模型参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "from ensemble import VoteEnsemble, StackingEnsemble\n",
    "from hyperparams_grid import *\n",
    "from utils import write_report_result, get_params_dict\n",
    "\n",
    "se_classifer = StackingEnsemble(algo)\n",
    "ve_classifer = VoteEnsemble(algo)\n",
    "\n",
    "def ensemble_predict(X, y, params_dict, default=False):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42) \n",
    "    se_predicted_targets = np.array([])\n",
    "    se_actual_targets = np.array([])\n",
    "    ve_predicted_targets = np.array([])\n",
    "    ve_actual_targets = np.array([])\n",
    "    se_model_scores, ve_model_scores = [], []\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        # set the parameter of the models first.\n",
    "        if default:\n",
    "            se_classifer.set_params()\n",
    "            ve_classifer.set_params()\n",
    "        else:\n",
    "            se_classifer.set_params(params_dict[fold-1])\n",
    "            ve_classifer.set_params(params_dict[fold-1])\n",
    "        # spilt train test\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        se_pred, se_acc, se_f1 = se_classifer.forward(train_X=X_train, train_y=y_train, test_X=X_test, test_y=y_test)\n",
    "        ve_pred, ve_acc, ve_f1 = ve_classifer.forward(train_X=X_train, train_y=y_train, test_X=X_test, test_y=y_test)\n",
    "        se_predicted_targets = np.append(se_predicted_targets, se_pred)\n",
    "        se_actual_targets = np.append(se_actual_targets, y_test)\n",
    "\n",
    "        print(f'Fold :{fold}\\n Stacking Ensemble Accuracy: {se_acc}, Stacking Ensemble F1: {se_f1}\\n Vote Ensemble Accuracy: {ve_acc}, Vote Ensemble F1: {ve_f1}')\n",
    "\n",
    "        ve_predicted_targets = np.append(ve_predicted_targets, ve_pred)\n",
    "        ve_actual_targets = np.append(ve_actual_targets, y_test)\n",
    "\n",
    "    se_model_scores.append([se_predicted_targets, se_actual_targets, 'se'])\n",
    "    ve_model_scores.append([ve_predicted_targets, ve_actual_targets, 've'])\n",
    "    \n",
    "    return se_model_scores + ve_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 4}}\n",
      "Fold :1\n",
      " Stacking Ensemble Accuracy: 1.0, Stacking Ensemble F1: 1.0\n",
      " Vote Ensemble Accuracy: 1.0, Vote Ensemble F1: 1.0\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 6}}\n",
      "Fold :2\n",
      " Stacking Ensemble Accuracy: 0.9722222222222222, Stacking Ensemble F1: 0.8571428571428571\n",
      " Vote Ensemble Accuracy: 1.0, Vote Ensemble F1: 1.0\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 2}}\n",
      "Fold :3\n",
      " Stacking Ensemble Accuracy: 1.0, Stacking Ensemble F1: 1.0\n",
      " Vote Ensemble Accuracy: 1.0, Vote Ensemble F1: 1.0\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 4}}\n",
      "Fold :4\n",
      " Stacking Ensemble Accuracy: 1.0, Stacking Ensemble F1: 1.0\n",
      " Vote Ensemble Accuracy: 1.0, Vote Ensemble F1: 1.0\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 4}}\n",
      "Fold :5\n",
      " Stacking Ensemble Accuracy: 0.9722222222222222, Stacking Ensemble F1: 0.6666666666666666\n",
      " Vote Ensemble Accuracy: 0.9722222222222222, Vote Ensemble F1: 0.6666666666666666\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 10}}\n",
      "Fold :6\n",
      " Stacking Ensemble Accuracy: 1.0, Stacking Ensemble F1: 1.0\n",
      " Vote Ensemble Accuracy: 1.0, Vote Ensemble F1: 1.0\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 6}}\n",
      "Fold :7\n",
      " Stacking Ensemble Accuracy: 0.9722222222222222, Stacking Ensemble F1: 0.6666666666666666\n",
      " Vote Ensemble Accuracy: 0.9722222222222222, Vote Ensemble F1: 0.6666666666666666\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 10}}\n",
      "Fold :8\n",
      " Stacking Ensemble Accuracy: 0.9722222222222222, Stacking Ensemble F1: 0.9090909090909091\n",
      " Vote Ensemble Accuracy: 0.9722222222222222, Vote Ensemble F1: 0.9090909090909091\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 4}}\n",
      "Fold :9\n",
      " Stacking Ensemble Accuracy: 0.9722222222222222, Stacking Ensemble F1: 0.8571428571428571\n",
      " Vote Ensemble Accuracy: 0.9722222222222222, Vote Ensemble F1: 0.8571428571428571\n",
      "{'DecisionTreeClassifier': {'criterion': 'entropy', 'max_depth': 12}}\n",
      "Fold :10\n",
      " Stacking Ensemble Accuracy: 1.0, Stacking Ensemble F1: 1.0\n",
      " Vote Ensemble Accuracy: 1.0, Vote Ensemble F1: 1.0\n",
      "[[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       1., 1., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       1., 1., 1.]), 'se'], [array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       1., 1., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       1., 1., 1.]), 've']]\n",
      "all\n",
      "se                  \n",
      "[[330   2]\n",
      " [  3  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       332\n",
      "         1.0       0.93      0.89      0.91        28\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.96      0.94      0.95       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "all\n",
      "ve                  \n",
      "[[331   2]\n",
      " [  2  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       333\n",
      "         1.0       0.93      0.93      0.93        27\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>se</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ve</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  precision    recall  f1-score\n",
       "0    se   0.925926  0.892857  0.909091\n",
       "1    ve   0.925926  0.925926  0.925926"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = LongMethod.to_numpy()\n",
    "y = LabelLongMethod.to_numpy()\n",
    "\n",
    "# 得到每一个fold的模型参数\n",
    "params_dict = get_params_dict(algo=algo, smelltype=smelltype)\n",
    "# 网格搜索集成模型\n",
    "model_scores = ensemble_predict(X, y, params_dict)\n",
    "write_report_result(model_scores, f\"tuning_model\\\\{smelltype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认参数集成模型\n",
    "\n",
    "model_scores = ensemble_predict(X, y, params_dict, default=True)\n",
    "write_report_result(model_scores, f\"default_model\\\\{smelltype}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
